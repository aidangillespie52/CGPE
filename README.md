# CGPE â€” Card Grading Profitability Engine

CGPE is a **data pipeline, analysis engine, and web app** for identifying **profitable trading cards to grade**, currently focused on PokÃ©mon.

It scrapes public market data, normalizes it into a stable schema, computes expected value using **population and price distributions**, and exposes results via both a **queryable database** and a **FastAPI web interface**. The system is designed to support future **signal generation** and **arbitrage research**, not automated execution.

---

## What CGPE Does

- Discovers sets, categories, and individual cards
- Scrapes raw population + pricing data concurrently
- Normalizes volatile HTML into stable domain models
- Persists results into SQLite as a single source of truth
- Computes expected value and profitability metrics
- Surfaces profitable cards via search and ranking views

**What it does *not* do (by design):**
- Place trades
- Auto-buy or auto-sell cards
- Circumvent site protections

---

## Key Features

- ğŸ” **Concurrent scraping** using `aiohttp`
- ğŸ§  **Expected value modeling** from real population + price distributions
- ğŸ’¾ **SQLite persistence** with repository-style access
- ğŸ§± **Clear separation of concerns** (scrape â†’ pipeline â†’ storage â†’ analysis)
- ğŸŒ **FastAPI web app** (search, card view, profit board)
- ğŸ“Š **Profit ranking & filtering**
- ğŸ“¡ **Signals & arbitrage research hooks** (non-executing)

---

## Project Structure

```text
CGPE/
â”œâ”€ cgpe/                     # main package
â”‚  â”œâ”€ analysis/              # EV + profitability calculations
â”‚  â”œâ”€ cli/                   # command-line tools
â”‚  â”œâ”€ config/                # scraper & source configuration
â”‚  â”œâ”€ http/                  # HTTP client, headers, rate limiting
â”‚  â”œâ”€ logging/               # structured logging
â”‚  â”œâ”€ models/                # core domain models (Detail, Set, etc.)
â”‚  â”œâ”€ pipeline/              # orchestration: scrape â†’ parse â†’ persist
â”‚  â”œâ”€ scrape/                # site-specific scraping & parsing
â”‚  â”‚  â”œâ”€ index/              # discovery (what sets exist)
â”‚  â”‚  â”œâ”€ category/           # category/list pages
â”‚  â”‚  â”œâ”€ set/                # set pages
â”‚  â”‚  â”œâ”€ detail/             # individual card pages
â”‚  â”‚  â””â”€ sources/            # per-site adapters & configs
â”‚  â”œâ”€ scripts/               # utilities (DB inspection, debugging)
â”‚  â”œâ”€ services/              # long-running jobs (backfills, refreshes)
â”‚  â”œâ”€ signals/               # arbitrage & profitability signal research
â”‚  â”œâ”€ storage/               # DB layer (repos, queries, sqlite)
â”‚  â”œâ”€ utils/                 # shared helpers
â”‚  â””â”€ web/                   # FastAPI app + UI
â”‚     â”œâ”€ services/           # web-facing service logic
â”‚     â”œâ”€ templates/          # Jinja templates
â”‚     â””â”€ static/             # CSS / assets
â”œâ”€ arbitrage/                # experimental arbitrage research
â”œâ”€ data/                     # SQLite database
â”œâ”€ logs/                     # rotating logs
â”œâ”€ downloaded_files/         # transient runtime artifacts
â”œâ”€ Dockerfile
â”œâ”€ pyproject.toml
â”œâ”€ uv.lock
â””â”€ README.md